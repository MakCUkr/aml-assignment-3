{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhhxIveVrbrT",
        "outputId": "316862e2-f1fb-4909-849e-00ff116afe5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/171.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m163.8/171.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.40.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence_transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 sentence_transformers-2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TRzOkQPPrU0h"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MSefkcrjrU0j"
      },
      "outputs": [],
      "source": [
        "positive_samples_df = pd.read_csv(\"/content/Papers of Interest with Abstracts.csv\")\n",
        "positive_samples_df = positive_samples_df[[\"title\", \"abstract\",'url']]\n",
        "daily_papers_df = pd.read_csv(\"/content/Arxiv papers daily.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "-x-m24oTrU0k",
        "outputId": "48fc817b-4493-48ca-a9cd-5e4ec0787fa4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"positive_samples_df\",\n  \"rows\": 313,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 302,\n        \"samples\": [\n          \"Title:Papeos: Augmenting Research Papers with Talk Videos\",\n          \"Title:DBOS: A Proposal for a Data-Centric Operating System\",\n          \"Title:Learning to Learn Financial Networks for Optimising Momentum Strategies\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 302,\n        \"samples\": [\n          \"Abstract:Research consumption has been traditionally limited to the reading of academic papers-a static, dense, and formally written format. Alternatively, pre-recorded conference presentation videos, which are more dynamic, concise, and colloquial, have recently become more widely available but potentially under-utilized. In this work, we explore the design space and benefits for combining academic papers and talk videos to leverage their complementary nature to provide a rich and fluid research consumption experience. Based on formative and co-design studies, we present Papeos, a novel reading and authoring interface that allow authors to augment their papers by segmenting and localizing talk videos alongside relevant paper passages with automatically generated suggestions. With Papeos, readers can visually skim a paper through clip thumbnails, and fluidly switch between consuming dense text in the paper or visual summaries in the video. In a comparative lab study (n=16), Papeos reduced mental load, scaffolded navigation, and facilitated more comprehensive reading of papers.\",\n          \"Abstract:Current operating systems are complex systems that were designed before today's computing environments. This makes it difficult for them to meet the scalability, heterogeneity, availability, and security challenges in current cloud and parallel computing environments. To address these problems, we propose a radically new OS design based on data-centric architecture: all operating system state should be represented uniformly as database tables, and operations on this state should be made via queries from otherwise stateless tasks. This design makes it easy to scale and evolve the OS without whole-system refactoring, inspect and debug system state, upgrade components without downtime, manage decisions using machine learning, and implement sophisticated security features. We discuss how a database OS (DBOS) can improve the programmability and performance of many of today's most important applications and propose a plan for the development of a DBOS proof of concept.\",\n          \"Abstract:Network momentum provides a novel type of risk premium, which exploits the interconnections among assets in a financial network to predict future returns. However, the current process of constructing financial networks relies heavily on expensive databases and financial expertise, limiting accessibility for small-sized and academic institutions. Furthermore, the traditional approach treats network construction and portfolio optimisation as separate tasks, potentially hindering optimal portfolio performance. To address these challenges, we propose L2GMOM, an end-to-end machine learning framework that simultaneously learns financial networks and optimises trading signals for network momentum strategies. The model of L2GMOM is a neural network with a highly interpretable forward propagation architecture, which is derived from algorithm unrolling. The L2GMOM is flexible and can be trained with diverse loss functions for portfolio performance, e.g. the negative Sharpe ratio. Backtesting on 64 continuous future contracts demonstrates a significant improvement in portfolio profitability and risk control, with a Sharpe ratio of 1.74 across a 20-year period.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 302,\n        \"samples\": [\n          \"https://arxiv.org/abs/2308.15224\",\n          \"https://arxiv.org/abs/2007.11112\",\n          \"https://arxiv.org/abs/2308.12212\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 302,\n        \"samples\": [\n          \"Title:Papeos: Augmenting Research Papers with Talk Videos Abstract:Research consumption has been traditionally limited to the reading of academic papers-a static, dense, and formally written format. Alternatively, pre-recorded conference presentation videos, which are more dynamic, concise, and colloquial, have recently become more widely available but potentially under-utilized. In this work, we explore the design space and benefits for combining academic papers and talk videos to leverage their complementary nature to provide a rich and fluid research consumption experience. Based on formative and co-design studies, we present Papeos, a novel reading and authoring interface that allow authors to augment their papers by segmenting and localizing talk videos alongside relevant paper passages with automatically generated suggestions. With Papeos, readers can visually skim a paper through clip thumbnails, and fluidly switch between consuming dense text in the paper or visual summaries in the video. In a comparative lab study (n=16), Papeos reduced mental load, scaffolded navigation, and facilitated more comprehensive reading of papers.\",\n          \"Title:DBOS: A Proposal for a Data-Centric Operating System Abstract:Current operating systems are complex systems that were designed before today's computing environments. This makes it difficult for them to meet the scalability, heterogeneity, availability, and security challenges in current cloud and parallel computing environments. To address these problems, we propose a radically new OS design based on data-centric architecture: all operating system state should be represented uniformly as database tables, and operations on this state should be made via queries from otherwise stateless tasks. This design makes it easy to scale and evolve the OS without whole-system refactoring, inspect and debug system state, upgrade components without downtime, manage decisions using machine learning, and implement sophisticated security features. We discuss how a database OS (DBOS) can improve the programmability and performance of many of today's most important applications and propose a plan for the development of a DBOS proof of concept.\",\n          \"Title:Learning to Learn Financial Networks for Optimising Momentum Strategies Abstract:Network momentum provides a novel type of risk premium, which exploits the interconnections among assets in a financial network to predict future returns. However, the current process of constructing financial networks relies heavily on expensive databases and financial expertise, limiting accessibility for small-sized and academic institutions. Furthermore, the traditional approach treats network construction and portfolio optimisation as separate tasks, potentially hindering optimal portfolio performance. To address these challenges, we propose L2GMOM, an end-to-end machine learning framework that simultaneously learns financial networks and optimises trading signals for network momentum strategies. The model of L2GMOM is a neural network with a highly interpretable forward propagation architecture, which is derived from algorithm unrolling. The L2GMOM is flexible and can be trained with diverse loss functions for portfolio performance, e.g. the negative Sharpe ratio. Backtesting on 64 continuous future contracts demonstrates a significant improvement in portfolio profitability and risk control, with a Sharpe ratio of 1.74 across a 20-year period.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "positive_samples_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-9ec87885-e802-4440-a353-12c72c3f68f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>url</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Title:A Generalist Neural Algorithmic Learner</td>\n",
              "      <td>Abstract:The cornerstone of neural algorithmic...</td>\n",
              "      <td>https://arxiv.org/abs/2209.11142</td>\n",
              "      <td>Title:A Generalist Neural Algorithmic Learner ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Title:Meta-Learning Fast Weight Language Models</td>\n",
              "      <td>Abstract:Dynamic evaluation of language models...</td>\n",
              "      <td>https://arxiv.org/abs/2212.02475</td>\n",
              "      <td>Title:Meta-Learning Fast Weight Language Model...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Title:Testing GLOM's ability to infer wholes f...</td>\n",
              "      <td>Abstract:The GLOM architecture proposed by Hin...</td>\n",
              "      <td>https://arxiv.org/abs/2211.16564</td>\n",
              "      <td>Title:Testing GLOM's ability to infer wholes f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Title:Seven Sketches in Compositionality: An I...</td>\n",
              "      <td>Abstract:This book is an invitation to discove...</td>\n",
              "      <td>https://arxiv.org/abs/1803.05316</td>\n",
              "      <td>Title:Seven Sketches in Compositionality: An I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Title:Evolution through Large Models</td>\n",
              "      <td>Abstract:This paper pursues the insight that l...</td>\n",
              "      <td>https://arxiv.org/abs/2206.08896</td>\n",
              "      <td>Title:Evolution through Large Models Abstract:...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ec87885-e802-4440-a353-12c72c3f68f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9ec87885-e802-4440-a353-12c72c3f68f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9ec87885-e802-4440-a353-12c72c3f68f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-81ac6c2b-6d79-4443-b0c5-0753f583f422\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-81ac6c2b-6d79-4443-b0c5-0753f583f422')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-81ac6c2b-6d79-4443-b0c5-0753f583f422 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                               title  \\\n",
              "0      Title:A Generalist Neural Algorithmic Learner   \n",
              "1    Title:Meta-Learning Fast Weight Language Models   \n",
              "2  Title:Testing GLOM's ability to infer wholes f...   \n",
              "3  Title:Seven Sketches in Compositionality: An I...   \n",
              "4               Title:Evolution through Large Models   \n",
              "\n",
              "                                            abstract  \\\n",
              "0  Abstract:The cornerstone of neural algorithmic...   \n",
              "1  Abstract:Dynamic evaluation of language models...   \n",
              "2  Abstract:The GLOM architecture proposed by Hin...   \n",
              "3  Abstract:This book is an invitation to discove...   \n",
              "4  Abstract:This paper pursues the insight that l...   \n",
              "\n",
              "                                url  \\\n",
              "0  https://arxiv.org/abs/2209.11142   \n",
              "1  https://arxiv.org/abs/2212.02475   \n",
              "2  https://arxiv.org/abs/2211.16564   \n",
              "3  https://arxiv.org/abs/1803.05316   \n",
              "4  https://arxiv.org/abs/2206.08896   \n",
              "\n",
              "                                                text  \n",
              "0  Title:A Generalist Neural Algorithmic Learner ...  \n",
              "1  Title:Meta-Learning Fast Weight Language Model...  \n",
              "2  Title:Testing GLOM's ability to infer wholes f...  \n",
              "3  Title:Seven Sketches in Compositionality: An I...  \n",
              "4  Title:Evolution through Large Models Abstract:...  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "positive_samples_df[\"text\"] = positive_samples_df[\"title\"] + \" \" + positive_samples_df[\"abstract\"]\n",
        "daily_papers_df[\"text\"] = daily_papers_df[\"title\"] + \" \" + daily_papers_df[\"abstract\"]\n",
        "positive_samples_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "hleHBc3PrU0k",
        "outputId": "188c3ef9-6312-4acd-e65a-fdefaad0a14e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1173\n",
            "1173\n",
            "1173\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"recommended_papers\",\n  \"rows\": 1173,\n  \"fields\": [\n    {\n      \"column\": \"Paper_ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 891,\n        \"samples\": [\n          \"http://arxiv.org/abs/2404.09625v1\",\n          \"oai:arXiv.org:2307.09591v2\",\n          \"http://arxiv.org/abs/2404.15261v1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 891,\n        \"samples\": [\n          \"Privacy-Preserving Intrusion Detection using Convolutional Neural\\r\\n  Networks\",\n          \"Gradient strikes back: How filtering out high frequencies improves explanations\",\n          \"All You Need is Resistance: On the Equivalence of Effective Resistance\\r\\n  and Certain Optimal Transport Problems on Graphs\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 891,\n        \"samples\": [\n          \"Privacy-preserving analytics is designed to protect valuable assets. A common service provision involves the input data from the client and the model on the analyst's side. The importance of the privacy preservation is fuelled by legal obligations and intellectual property concerns. We explore the use case of a model owner providing an analytic service on customer's private data. No information about the data shall be revealed to the analyst and no information about the model shall be leaked to the customer. Current methods involve costs: accuracy deterioration and computational complexity. The complexity, in turn, results in a longer processing time, increased requirement on computing resources, and involves data communication between the client and the server. In order to deploy such service architecture, we need to evaluate the optimal setting that fits the constraints. And that is what this paper addresses. In this work, we enhance an attack detection system based on Convolutional Neural Networks with privacy-preserving technology based on PriMIA framework that is initially designed for medical data.\",\n          \"arXiv:2307.09591v2 Announce Type: replace-cross  Abstract: Attribution methods correspond to a class of explainability methods (XAI) that aim to assess how individual inputs contribute to a model's decision-making process. We have identified a significant limitation in one type of attribution methods, known as \\\"white-box\\\" methods. Although highly efficient, these methods rely on a gradient signal that is often contaminated by high-frequency noise. To overcome this limitation, we introduce a new approach called \\\"FORGrad\\\". This simple method effectively filters out noise artifacts by using optimal cut-off frequencies tailored to the unique characteristics of each model architecture. Our findings show that FORGrad consistently enhances the performance of already existing white-box methods, enabling them to compete effectively with more accurate yet computationally demanding \\\"black-box\\\" methods. We anticipate that our research will foster broader adoption of simpler and more efficient white-box methods for explainability, offering a better balance between faithfulness and computational efficiency.\",\n          \"The fields of effective resistance and optimal transport on graphs are filled with rich connections to combinatorics, geometry, machine learning, and beyond. In this article we put forth a bold claim: that the two fields should be understood as one and the same, up to a choice of $p$. We make this claim precise by introducing the parameterized family of $p$-Beckmann distances for probability measures on graphs and relate them sharply to certain Wasserstein distances. Then, we break open a suite of results including explicit connections to optimal stopping times and random walks on graphs, graph Sobolev spaces, and a Benamou-Brenier type formula for $2$-Beckmann distance. We further explore empirical implications in the world of unsupervised learning for graph data and propose further study of the usage of these metrics where Wasserstein distance may produce computational bottlenecks.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Most_Similar_Paper_ID\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 217,\n        \"samples\": [\n          \"https://arxiv.org/abs/2302.09425\",\n          \"https://arxiv.org/abs/2401.06104\",\n          \"https://arxiv.org/abs/2010.01265\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Similarity_Score\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 892,\n        \"samples\": [\n          0.45429518818855286,\n          0.5306663513183594,\n          0.50691819190979\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "recommended_papers"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-277de25e-b901-4947-a128-97e44ab27aa2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Paper_ID</th>\n",
              "      <th>Title</th>\n",
              "      <th>Abstract</th>\n",
              "      <th>Most_Similar_Paper_ID</th>\n",
              "      <th>Similarity_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>408</th>\n",
              "      <td>http://arxiv.org/abs/2404.11483v1</td>\n",
              "      <td>AgentKit: Flow Engineering with Graphs, not Co...</td>\n",
              "      <td>We propose an intuitive LLM prompting framewor...</td>\n",
              "      <td>https://arxiv.org/abs/2404.11483v1</td>\n",
              "      <td>0.992351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>http://arxiv.org/abs/2404.10308v1</td>\n",
              "      <td>Hierarchical Context Merging: Better Long Cont...</td>\n",
              "      <td>Large language models (LLMs) have shown remark...</td>\n",
              "      <td>https://arxiv.org/abs/2304.11062</td>\n",
              "      <td>0.779029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>oai:arXiv.org:2403.19888v1</td>\n",
              "      <td>MambaMixer: Efficient Selective State Space Mo...</td>\n",
              "      <td>arXiv:2403.19888v1 Announce Type: new  Abstrac...</td>\n",
              "      <td>https://arxiv.org/abs/2312.00752</td>\n",
              "      <td>0.769301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>http://arxiv.org/abs/2404.11925v1</td>\n",
              "      <td>EdgeFusion: On-Device Text-to-Image Generation</td>\n",
              "      <td>The intensive computational burden of Stable D...</td>\n",
              "      <td>https://arxiv.org/abs/2303.01469</td>\n",
              "      <td>0.754476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>677</th>\n",
              "      <td>http://arxiv.org/abs/2404.11925v1</td>\n",
              "      <td>EdgeFusion: On-Device Text-to-Image Generation</td>\n",
              "      <td>The intensive computational burden of Stable D...</td>\n",
              "      <td>https://arxiv.org/abs/2303.01469</td>\n",
              "      <td>0.754476</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-277de25e-b901-4947-a128-97e44ab27aa2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-277de25e-b901-4947-a128-97e44ab27aa2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-277de25e-b901-4947-a128-97e44ab27aa2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cbfb9a6e-9506-4763-9367-5644aebcec5e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cbfb9a6e-9506-4763-9367-5644aebcec5e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cbfb9a6e-9506-4763-9367-5644aebcec5e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                              Paper_ID  \\\n",
              "408  http://arxiv.org/abs/2404.11483v1   \n",
              "370  http://arxiv.org/abs/2404.10308v1   \n",
              "14          oai:arXiv.org:2403.19888v1   \n",
              "524  http://arxiv.org/abs/2404.11925v1   \n",
              "677  http://arxiv.org/abs/2404.11925v1   \n",
              "\n",
              "                                                 Title  \\\n",
              "408  AgentKit: Flow Engineering with Graphs, not Co...   \n",
              "370  Hierarchical Context Merging: Better Long Cont...   \n",
              "14   MambaMixer: Efficient Selective State Space Mo...   \n",
              "524     EdgeFusion: On-Device Text-to-Image Generation   \n",
              "677     EdgeFusion: On-Device Text-to-Image Generation   \n",
              "\n",
              "                                              Abstract  \\\n",
              "408  We propose an intuitive LLM prompting framewor...   \n",
              "370  Large language models (LLMs) have shown remark...   \n",
              "14   arXiv:2403.19888v1 Announce Type: new  Abstrac...   \n",
              "524  The intensive computational burden of Stable D...   \n",
              "677  The intensive computational burden of Stable D...   \n",
              "\n",
              "                  Most_Similar_Paper_ID  Similarity_Score  \n",
              "408  https://arxiv.org/abs/2404.11483v1          0.992351  \n",
              "370    https://arxiv.org/abs/2304.11062          0.779029  \n",
              "14     https://arxiv.org/abs/2312.00752          0.769301  \n",
              "524    https://arxiv.org/abs/2303.01469          0.754476  \n",
              "677    https://arxiv.org/abs/2303.01469          0.754476  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = SentenceTransformer('all-MiniLM-L6-v2').to('cuda')\n",
        "positive_samples_embeddings = model.encode(positive_samples_df['text'].tolist(), convert_to_tensor=True)\n",
        "daily_papers_embeddings = model.encode(daily_papers_df['text'].tolist(), convert_to_tensor=True)\n",
        "\n",
        "# Calculate cosine similarities between embeddings\n",
        "cosine_similarities_embeddings = cosine_similarity(daily_papers_embeddings.cpu(), positive_samples_embeddings.cpu())\n",
        "\n",
        "# Get the most similar papers based on the embeddings\n",
        "max_similarity_indices = np.argmax(cosine_similarities_embeddings, axis=1)\n",
        "max_similarity_scores = np.max(cosine_similarities_embeddings, axis=1)\n",
        "\n",
        "recommended_papers = pd.DataFrame({\n",
        "    'Paper_ID': daily_papers_df['id'].values,  # Using .values to ensure correct handling\n",
        "    'Title': daily_papers_df['title'].values,\n",
        "    'Abstract': daily_papers_df['abstract'].values,\n",
        "    'Most_Similar_Paper_ID': positive_samples_df['url'].iloc[max_similarity_indices].values,  # Added .values\n",
        "    'Similarity_Score': max_similarity_scores\n",
        "}, index=daily_papers_df.index)\n",
        "recommended_papers.sort_values('Similarity_Score', ascending=False, inplace=True)\n",
        "recommended_papers.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8A-JkiFU2F7Q",
        "outputId": "63202575-6b65-42b2-d9d2-b438893b077c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([313, 384])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "positive_samples_embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "eyKyfFjCrU0l"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.dense1 = torch.nn.Linear(384*2,128)\n",
        "    self.dense2 = torch.nn.Linear(128,32)\n",
        "    self.dropout=torch.nn.Dropout(0.2)\n",
        "    self.dense3 = torch.nn.Linear(32,2)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.dense1(x)\n",
        "    x = self.dropout(x)\n",
        "    x = torch.tanh(x)\n",
        "    x = self.dense2(x)\n",
        "    x = self.dropout(x)\n",
        "    x = torch.tanh(x)\n",
        "    x = self.dense3(x)\n",
        "    x = self.dropout(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le4NZHWmrU0l",
        "outputId": "b9e9ec39-9fd8-453b-e33b-56f27274f9aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50, Loss: 0.6157299739283484\n",
            "Epoch 2/50, Loss: 0.4442987305087012\n",
            "Epoch 3/50, Loss: 0.38674108200782054\n",
            "Epoch 4/50, Loss: 0.3500854763630274\n",
            "Epoch 5/50, Loss: 0.2991571059903583\n",
            "Epoch 6/50, Loss: 0.30913969673014974\n",
            "Epoch 7/50, Loss: 0.2960251473091744\n",
            "Epoch 8/50, Loss: 0.2933818943597175\n",
            "Epoch 9/50, Loss: 0.27052644096516276\n",
            "Epoch 10/50, Loss: 0.24435682776006493\n",
            "Epoch 11/50, Loss: 0.19857612131415187\n",
            "Epoch 12/50, Loss: 0.20150517068199209\n",
            "Epoch 13/50, Loss: 0.2321770169042252\n",
            "Epoch 14/50, Loss: 0.1686284667938142\n",
            "Epoch 15/50, Loss: 0.2155486989665676\n",
            "Epoch 16/50, Loss: 0.24081728808783195\n",
            "Epoch 17/50, Loss: 0.19738252340136347\n",
            "Epoch 18/50, Loss: 0.2044869368342129\n",
            "Epoch 19/50, Loss: 0.2042288156981404\n",
            "Epoch 20/50, Loss: 0.192197929362993\n",
            "Epoch 21/50, Loss: 0.1972490300399226\n",
            "Epoch 22/50, Loss: 0.16479397595331474\n",
            "Epoch 23/50, Loss: 0.17632675533359116\n",
            "Epoch 24/50, Loss: 0.1544790618322991\n",
            "Epoch 25/50, Loss: 0.19191016508518038\n",
            "Epoch 26/50, Loss: 0.17890713283339063\n",
            "Epoch 27/50, Loss: 0.21004779314672625\n",
            "Epoch 28/50, Loss: 0.16187664655012055\n",
            "Epoch 29/50, Loss: 0.1640124401530704\n",
            "Epoch 30/50, Loss: 0.15153942468601303\n",
            "Epoch 31/50, Loss: 0.14520517595716426\n",
            "Epoch 32/50, Loss: 0.15838049311895627\n",
            "Epoch 33/50, Loss: 0.15158824803861412\n",
            "Epoch 34/50, Loss: 0.16454278259865335\n",
            "Epoch 35/50, Loss: 0.18123489049439495\n",
            "Epoch 36/50, Loss: 0.14498582140013977\n",
            "Epoch 37/50, Loss: 0.15969499764410225\n",
            "Epoch 38/50, Loss: 0.14219907006701907\n",
            "Epoch 39/50, Loss: 0.17338197119534016\n",
            "Epoch 40/50, Loss: 0.13578219651370435\n",
            "Epoch 41/50, Loss: 0.1583284213635567\n",
            "Epoch 42/50, Loss: 0.14473056903964765\n",
            "Epoch 43/50, Loss: 0.13899044194132895\n",
            "Epoch 44/50, Loss: 0.14436502286509886\n",
            "Epoch 45/50, Loss: 0.14515237706537182\n",
            "Epoch 46/50, Loss: 0.13302404201916745\n",
            "Epoch 47/50, Loss: 0.133963804893397\n",
            "Epoch 48/50, Loss: 0.12449040367091829\n",
            "Epoch 49/50, Loss: 0.16752295931046074\n",
            "Epoch 50/50, Loss: 0.1659847890354089\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from random import randint, random\n",
        "import numpy as np\n",
        "\n",
        "# Assuming your model is already defined as Net and moved to CUDA\n",
        "model = Net().cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Convert DataFrame texts to embeddings\n",
        "# Assuming these functions are already defined and moved to cuda\n",
        "# positive_samples_embeddings and daily_papers_embeddings\n",
        "\n",
        "# Create a dataset\n",
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, positive_samples_embeddings, daily_papers_embeddings):\n",
        "        self.positive_samples_embeddings = positive_samples_embeddings\n",
        "        self.daily_papers_embeddings = daily_papers_embeddings\n",
        "\n",
        "    def __len__(self):\n",
        "        # Assuming the number of daily papers is the limiting factor\n",
        "        return len(self.daily_papers_embeddings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pos_sample = self.positive_samples_embeddings[randint(0, len(self.positive_samples_embeddings) - 1)]\n",
        "        daily_paper = self.daily_papers_embeddings[idx]\n",
        "        another_daily = self.daily_papers_embeddings[randint(0, len(self.daily_papers_embeddings) - 1)]\n",
        "\n",
        "        if random() > 0.5:\n",
        "            # 50% chance to pair with a positive sample, label is 1\n",
        "            return torch.cat((pos_sample, daily_paper), dim=0), torch.tensor([1])\n",
        "        else:\n",
        "            # 50% chance to pair with another daily paper, label is 0\n",
        "            return torch.cat((daily_paper, another_daily), dim=0), torch.tensor([0])\n",
        "\n",
        "# Create DataLoader\n",
        "dataset = MyDataset(positive_samples_embeddings, daily_papers_embeddings)\n",
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 50\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for data, labels in data_loader:\n",
        "        data, labels = data.cuda(), labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, labels.squeeze(1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(data_loader)}\")\n",
        "\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "4nxmRXCc5hg_",
        "outputId": "b5528430-4501-4f9f-828f-ec0091f4e12d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"recommended_papers\",\n  \"rows\": 1173,\n  \"fields\": [\n    {\n      \"column\": \"Paper_ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 891,\n        \"samples\": [\n          \"http://arxiv.org/abs/2404.15149v1\",\n          \"http://arxiv.org/abs/2404.12667v1\",\n          \"http://arxiv.org/abs/2404.10494v1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 891,\n        \"samples\": [\n          \"Bias patterns in the application of LLMs for clinical decision support:\\r\\n  A comprehensive study\",\n          \"Detecting Out-Of-Distribution Earth Observation Images with Diffusion\\r\\n  Models\",\n          \"BDAN: Mitigating Temporal Difference Across Electrodes in Cross-Subject\\r\\n  Motor Imagery Classification via Generative Bridging Domain\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 891,\n        \"samples\": [\n          \"Large Language Models (LLMs) have emerged as powerful candidates to inform clinical decision-making processes. While these models play an increasingly prominent role in shaping the digital landscape, two growing concerns emerge in healthcare applications: 1) to what extent do LLMs exhibit social bias based on patients' protected attributes (like race), and 2) how do design choices (like architecture design and prompting strategies) influence the observed biases? To answer these questions rigorously, we evaluated eight popular LLMs across three question-answering (QA) datasets using clinical vignettes (patient descriptions) standardized for bias evaluations. We employ red-teaming strategies to analyze how demographics affect LLM outputs, comparing both general-purpose and clinically-trained models. Our extensive experiments reveal various disparities (some significant) across protected groups. We also observe several counter-intuitive patterns such as larger models not being necessarily less biased and fined-tuned models on medical data not being necessarily better than the general-purpose models. Furthermore, our study demonstrates the impact of prompt design on bias patterns and shows that specific phrasing can influence bias patterns and reflection-type approaches (like Chain of Thought) can reduce biased outcomes effectively. Consistent with prior studies, we call on additional evaluations, scrutiny, and enhancement of LLMs used in clinical decision support applications.\",\n          \"Earth Observation imagery can capture rare and unusual events, such as disasters and major landscape changes, whose visual appearance contrasts with the usual observations. Deep models trained on common remote sensing data will output drastically different features for these out-of-distribution samples, compared to those closer to their training dataset. Detecting them could therefore help anticipate changes in the observations, either geographical or environmental. In this work, we show that the reconstruction error of diffusion models can effectively serve as unsupervised out-of-distribution detectors for remote sensing images, using them as a plausibility score. Moreover, we introduce ODEED, a novel reconstruction-based scorer using the probability-flow ODE of diffusion models. We validate it experimentally on SpaceNet 8 with various scenarios, such as classical OOD detection with geographical shift and near-OOD setups: pre/post-flood and non-flooded/flooded image recognition. We show that our ODEED scorer significantly outperforms other diffusion-based and discriminative baselines on the more challenging near-OOD scenarios of flood image detection, where OOD images are close to the distribution tail. We aim to pave the way towards better use of generative models for anomaly detection in remote sensing.\",\n          \"Because of \\\"the non-repeatability of the experiment settings and conditions\\\" and \\\"the variability of brain patterns among subjects\\\", the data distributions across sessions and electrodes are different in cross-subject motor imagery (MI) studies, eventually reducing the performance of the classification model. Systematically summarised based on the existing studies, a novel temporal-electrode data distribution problem is investigated under both intra-subject and inter-subject scenarios in this paper. Based on the presented issue, a novel bridging domain adaptation network (BDAN) is proposed, aiming to minimise the data distribution difference across sessions in the aspect of the electrode, thus improving and enhancing model performance. In the proposed BDAN, deep features of all the EEG data are extracted via a specially designed spatial feature extractor. With the obtained spatio-temporal features, a special generative bridging domain is established, bridging the data from all the subjects across sessions. The difference across sessions and electrodes is then minimized using the customized bridging loss functions, and the known knowledge is automatically transferred through the constructed bridging domain. To show the effectiveness of the proposed BDAN, comparison experiments and ablation studies are conducted on a public EEG dataset. The overall comparison results demonstrate the superior performance of the proposed BDAN compared with the other advanced deep learning and domain adaptation methods.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Most_Similar_Paper_ID\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"https://arxiv.org/abs/2312.03173\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Similarity_Score\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 892,\n        \"samples\": [\n          6.461679004132748e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "recommended_papers"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-88f97576-59db-45b1-aa01-daf3c7ed9a53\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Paper_ID</th>\n",
              "      <th>Title</th>\n",
              "      <th>Abstract</th>\n",
              "      <th>Most_Similar_Paper_ID</th>\n",
              "      <th>Similarity_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>733</th>\n",
              "      <td>http://arxiv.org/abs/2404.12803v1</td>\n",
              "      <td>TextSquare: Scaling up Text-Centric Visual Ins...</td>\n",
              "      <td>Text-centric visual question answering (VQA) h...</td>\n",
              "      <td>https://arxiv.org/abs/2312.03173</td>\n",
              "      <td>0.999340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1119</th>\n",
              "      <td>http://arxiv.org/abs/2404.17563v1</td>\n",
              "      <td>An exactly solvable model for emergence and sc...</td>\n",
              "      <td>Deep learning models can exhibit what appears ...</td>\n",
              "      <td>https://arxiv.org/abs/2312.03173</td>\n",
              "      <td>0.999044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>726</th>\n",
              "      <td>http://arxiv.org/abs/2404.12843v1</td>\n",
              "      <td>Towards Logically Consistent Language Models v...</td>\n",
              "      <td>Large language models (LLMs) are a promising v...</td>\n",
              "      <td>https://arxiv.org/abs/2312.03173</td>\n",
              "      <td>0.998964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>873</th>\n",
              "      <td>http://arxiv.org/abs/2404.14994v1</td>\n",
              "      <td>Transformers Can Represent $n$-gram Language M...</td>\n",
              "      <td>Plenty of existing work has analyzed the abili...</td>\n",
              "      <td>https://arxiv.org/abs/2312.03173</td>\n",
              "      <td>0.998790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>770</th>\n",
              "      <td>http://arxiv.org/abs/2404.12596v1</td>\n",
              "      <td>Parameter Efficient Diverse Paraphrase Generat...</td>\n",
              "      <td>Over the past year, the field of Natural Langu...</td>\n",
              "      <td>https://arxiv.org/abs/2312.03173</td>\n",
              "      <td>0.998704</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88f97576-59db-45b1-aa01-daf3c7ed9a53')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-88f97576-59db-45b1-aa01-daf3c7ed9a53 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-88f97576-59db-45b1-aa01-daf3c7ed9a53');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-83b42586-96b4-44bf-ab98-1cbbe42b7b13\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-83b42586-96b4-44bf-ab98-1cbbe42b7b13')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-83b42586-96b4-44bf-ab98-1cbbe42b7b13 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                               Paper_ID  \\\n",
              "733   http://arxiv.org/abs/2404.12803v1   \n",
              "1119  http://arxiv.org/abs/2404.17563v1   \n",
              "726   http://arxiv.org/abs/2404.12843v1   \n",
              "873   http://arxiv.org/abs/2404.14994v1   \n",
              "770   http://arxiv.org/abs/2404.12596v1   \n",
              "\n",
              "                                                  Title  \\\n",
              "733   TextSquare: Scaling up Text-Centric Visual Ins...   \n",
              "1119  An exactly solvable model for emergence and sc...   \n",
              "726   Towards Logically Consistent Language Models v...   \n",
              "873   Transformers Can Represent $n$-gram Language M...   \n",
              "770   Parameter Efficient Diverse Paraphrase Generat...   \n",
              "\n",
              "                                               Abstract  \\\n",
              "733   Text-centric visual question answering (VQA) h...   \n",
              "1119  Deep learning models can exhibit what appears ...   \n",
              "726   Large language models (LLMs) are a promising v...   \n",
              "873   Plenty of existing work has analyzed the abili...   \n",
              "770   Over the past year, the field of Natural Langu...   \n",
              "\n",
              "                 Most_Similar_Paper_ID  Similarity_Score  \n",
              "733   https://arxiv.org/abs/2312.03173          0.999340  \n",
              "1119  https://arxiv.org/abs/2312.03173          0.999044  \n",
              "726   https://arxiv.org/abs/2312.03173          0.998964  \n",
              "873   https://arxiv.org/abs/2312.03173          0.998790  \n",
              "770   https://arxiv.org/abs/2312.03173          0.998704  "
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Prepare DataLoader for all combinations\n",
        "class CombinationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, daily_papers_embeddings, positive_samples_embeddings):\n",
        "        self.daily_papers_embeddings = daily_papers_embeddings\n",
        "        self.pmodel.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# DataLoader for evaluating every positive sample with each daily paper\n",
        "class CombinationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, daily_papers_embeddings, positive_samples_embeddings):\n",
        "        self.daily_papers_embeddings = daily_papers_embeddings\n",
        "        self.positive_samples_embeddings = positive_samples_embeddings\n",
        "\n",
        "    def __len__(self):\n",
        "        # Total combinations\n",
        "        return len(self.daily_papers_embeddings) * len(self.positive_samples_embeddings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        num_pos_samples = len(self.positive_samples_embeddings)\n",
        "        daily_idx = idx // num_pos_samples\n",
        "        pos_idx = idx % num_pos_samples\n",
        "        combined_embedding = torch.cat((self.daily_papers_embeddings[daily_idx], self.positive_samples_embeddings[pos_idx]), dim=0)\n",
        "        return combined_embedding, daily_idx, pos_idx\n",
        "\n",
        "combination_dataset = CombinationDataset(daily_papers_embeddings, positive_samples_embeddings)\n",
        "combination_loader = DataLoader(combination_dataset, batch_size=1024, shuffle=False)\n",
        "\n",
        "# Initialize arrays to track the best positive samples and their probabilities\n",
        "max_probabilities = torch.full((len(daily_papers_embeddings),), -1.0, device='cuda')\n",
        "best_pos_indices = torch.zeros(len(daily_papers_embeddings), dtype=torch.long, device='cuda')\n",
        "\n",
        "with torch.no_grad():\n",
        "    for embeddings, daily_indices, pos_indices in combination_loader:\n",
        "        embeddings = embeddings.cuda()\n",
        "        outputs = model(embeddings)\n",
        "        probabilities = torch.nn.functional.softmax(outputs, dim=1)[:, 1]  # Probabilities for label '1'\n",
        "\n",
        "        for i in range(len(probabilities)):\n",
        "            daily_idx = daily_indices[i].item()\n",
        "            pos_idx = pos_indices[i].item()\n",
        "            prob = probabilities[i].item()\n",
        "            if prob > max_probabilities[daily_idx]:\n",
        "                max_probabilities[daily_idx] = prob\n",
        "                best_pos_indices[daily_idx] = pos_idx\n",
        "\n",
        "              #  print(daily_idx,pos_idx,prob)\n",
        "\n",
        "# Convert indices and probabilities to CPU for DataFrame creation\n",
        "best_pos_indices = best_pos_indices.cpu()\n",
        "max_probabilities = max_probabilities.cpu()\n",
        "\n",
        "recommended_papers = pd.DataFrame({\n",
        "    'Paper_ID': daily_papers_df['id'].values,\n",
        "    'Title': daily_papers_df['title'].values,\n",
        "    'Abstract': daily_papers_df['abstract'].values,\n",
        "    'Most_Similar_Paper_ID': positive_samples_df['url'].iloc[best_pos_indices].values,\n",
        "    'Similarity_Score': max_probabilities.numpy()\n",
        "}, index=daily_papers_df.index)\n",
        "recommended_papers.sort_values('Similarity_Score', ascending=False, inplace=True)\n",
        "recommended_papers.head(5)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
